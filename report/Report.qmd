---
title: "SBM Report Group 4"
format: html
editor: visual
author: "Bram, Diego, Roland, Thomas, Born√°"
bibliography: references.bib
---

# Report SBM Group 4

## Introduction

Introduce the topic, explain why it is interesting (the research gap and the practical relevance), and formulate the research question.

## Theory and Hypotheses

Explain the state of art in the relevant literature, building towards what is it exactly that you would like to research, consistent with your research question and research gap. If your research design allows for it, develop at most 3 hypotheses based on the theoretical framework you covered: what is it that you expect to see in the data, and why? (Include Behavioral Theory of the Firm).

### Assumptions

We assume that an entrepreneur does not have any prior experience. We assume that the data is sufficient. For a proxy of successrate, we use the funding as a measure. We assume that the funding is a good proxy for success, because if the funding is not met, the project will not be realized. We assume that the data is not biased, because the data is collected by a third party. We assume that the data is not biased, because the data is collected by a third party. We assume that innovation-related words can also be taken as meaning innovation. By expanding the bucket of words referring to innovation we assure that the majority of the words related to innovation are covered.

We do not assume that employees influence business results, as we are taking a look at Kickstarter projects. And start-up culture is not the same as corporate culture. We do not assume that the number of employees is a good proxy for experience, because the number of employees does not say anything about the experience of the employees [@martin2010].

### Research Question 1

How does experience impact the success rate?

Hypothesis 1: Experience will have a positive impact on whether the idea is successful.

### Research Question 2

How do business ideas change after experience?

Hypothesis 2: subsequent ideas are more innovative than the first idea.

## Methods and Data

Describe the data set that you used, the way you translated the raw data into variables, and the methods you used to analyze the data (e.g., cluster analysis, regression analysis, panel data analysis, time series). Remember that most methods have a number of assumptions that you have to check prior to doing the analyses. Certain assumption violations can be fixed by transforming the focal variables, e.g., the dependent variable, in case of other violations you may need to choose a different method.

```{r}
getwd()
setwd("C:/Users/Borna/Documents/Study/Masters/Master A/Strategy and Business Models/SBM_assignment/report")
getwd()
```

### Data Importing and cleaning, hypothesis 1

In order to test the first hypothesis it is necessary to first clean the data. The first step is to select the data that has a deadline is before week 32 in 2019 in unix time and make sure that the variables that will be used in the regression are of the correct class. Next, a percentage is derived from the pledge goal of the project and how much was actually pledged, this will be used as a measure of success. For this reason the projects with a pledge goal of 0 were removed, this avoids division by zero. It was also chosen that values that exceeded 100% would be set to this value, as these might be detected as outliers and could cause issues. After this, we check the distribution of the data and remove cases in which we don't have enough data for the number of projects backed and the number of projects created, which are proxies for learning in this study. We consider that having less than 50 data points is when the data point is removed, this is because 50 data points are the minimum for a normal distribution to be present (find citation). Finally, the null values are removed. The below shows the distribution of the learning proxies and the proxy for success.

```{r}

#inspect the data
info32

#create new data with only a few columns of info32 dataset
dataHyp1Sub <- info32[,c('Goal_USD','Pledge_USD','Launched_at','Deadline', 'Creator_nb_projects', 'Creator_nb_backed')]
#dataHyp1Sub

#make a subdataset where deadline is before week 32 in 2019 in unix time
dataHyp1 <- dataHyp1Sub[dataHyp1Sub$Deadline < 1565474400,]
#dataHyp1

#You drop only 1850 records out of 75000

#count the number of rows in dataHyp1sub and dataHyp1
nrow(dataHyp1Sub)
nrow(dataHyp1)


#columns to integer
dataHyp1$Pledge_USD <- as.integer(dataHyp1$Pledge_USD)
dataHyp1$Goal_USD <- as.integer(dataHyp1$Goal_USD)

#drop the rows where Goal_USD is 0 -> then you might get inf percentage
dataHyp1 <- dataHyp1[dataHyp1$Goal_USD != 0,]
#dataHyp1

#Create a new column with percentage of goal reached
dataHyp1$Goal_percentage <- dataHyp1$Pledge_USD/dataHyp1$Goal_USD
dataHyp1$Goal_percentage <- round(dataHyp1$Goal_percentage, digits = 3)
dataHyp1$Goal_percentage[dataHyp1$Goal_percentage>100] = 100
print(dataHyp1$Goal_percentage)
#dataHyp1

#Get from Creator_nb_backed only the number with a regex
dataHyp1$Creator_nb_backed <- gsub("[^0-9]", "", dataHyp1$Creator_nb_backed) #Seeing if this works better as a string rather than
#dataHyp1

#drop redundant columns
dataHyp1 <- dataHyp1[,c('Creator_nb_projects', 'Creator_nb_backed', 'Goal_percentage')]


#Drop the rows where nan values occur
dataHyp1 <- dataHyp1[complete.cases(dataHyp1),]


#dataHyp1#Columns as integers
#dataHyp1$Creator_nb_backed <- as.integer(dataHyp1$Creator_nb_backed)


#to find an appropriate cutoff point:
table(dataHyp1$Creator_nb_projects)
table(dataHyp1$Creator_nb_backed)

# we will only use values with at least 50 records, because for normal distribution you need a minimum of 50 values
# So then you have an substantial amount of values


#iterate over the values of the following table: table(dataHyp1$Creator_nb_projects)
quan_table1 = table(dataHyp1$Creator_nb_projects)
quan_table2 = table(dataHyp1$Creator_nb_backed)

#in quan_table, drop the records where the value is < 50
quan_table1 <- quan_table1[quan_table1 >= 50]
quan_table2 <- quan_table2[quan_table2 >= 50]

#clean the data such that only records with over 50 occurences are in there
dataHyp1_2 <- dataHyp1[dataHyp1$Creator_nb_projects %in% names(quan_table1),]
dataHyp1_2 <- dataHyp1[dataHyp1$Creator_nb_backed %in% names(quan_table2),]

#make a table of the values of Creator_nb_projects
table(dataHyp1_2$Creator_nb_projects)

#drop nan and inf values in dataHyp1_2
dataHyp1_2 <- dataHyp1_2[complete.cases(dataHyp1_2),]



x<-dataHyp1_2$Goal_percentage
##check the distribution of the outcome variable
hist(x)
table(x)
#looks exponential, so we try log transform
y<-log(dataHyp1_2$Goal_percentage+1)
qqnorm(y)
qqline(y)
#still skewed, so we try to include sqrt transform
y<-sqrt(log(dataHyp1_2$Goal_percentage+1))
qqnorm(y)
qqline(y)

#dataHyp1_2


####I think this below is the old stuff, the newer stuff contained percentages

#make a new column with boolean if goal_USD >= Pledge_USD
#dataHyp1$Goal_met <- dataHyp1$Goal_USD <= dataHyp1$Pledge_USD
#dataHyp1

#Get from Creator_nb_backed only the number with a regex
#dataHyp1$Creator_nb_backed <- as.integer(gsub("[^0-9]", "", dataHyp1$Creator_nb_backed))

#drop na values in dataHyp1
#dataHyp1 <- dataHyp1[complete.cases(dataHyp1),]
#dataHyp1 <- dataHyp1[,c('Creator_nb_projects', 'Creator_nb_backed', 'Goal_met')]
#dataHyp1


#change Goal_met to binary
#dataHyp1$Goal_met <- as.integer(dataHyp1$Goal_met)
#dataHyp1


#Columns as integers
#dataHyp1$Creator_nb_backed <- as.integer#(dataHyp1$Creator_nb_backed)


#to find an appropriate cutoff point:
#table(dataHyp1$Creator_nb_projects)

# we will only use values with at least 50 records, because for normal distribution you need a minimum of 50 values
# So then you have an substantial amount of values


#iterate over the values of the following table: table(dataHyp1$Creator_nb_projects)
#quan_table = table(dataHyp1$Creator_nb_projects)

#in quan_table, drop the records where the value is < 50
#quan_table <- quan_table[quan_table >= 50]

#clean the data such that only records with over 50 occurences are in there
#dataHyp1_2 <- dataHyp1[dataHyp1$Creator_nb_projects %in% names(quan_table),]

#make a table of the values of Creator_nb_projects
#table(dataHyp1_2$Creator_nb_projects)



```

Next we check the distribution of the success proxy. We notice that it is not normal, so a couple of transformations are tried. First Log(x+1) is tried, given that 0% is still viable, this shift is necessary to avoid undefined values. Next sqrt(Log(x+1)) is applied, but even though it is better, with the QQ-plots below we notice that it is still not normally distributed. The first QQ-plot corresponds to Log(x+1) and the second is for sqrt(Log(x+1)). Therefore a Linear Regression model cannot be used.

```{r}
x<-dataHyp1_2$Goal_percentage
##check the distribution of the outcome variable
hist(x)
table(x)
#looks exponential, so we try log transform
y<-log(dataHyp1_2$Goal_percentage+1)
qqnorm(y)
qqline(y)
#still skewed, so we try to include sqrt transform
y<-sqrt(log(dataHyp1_2$Goal_percentage+1))
qqnorm(y)
qqline(y)


```

### Regression and Anova test, hypothesis 1

```{r}





###This is also old for the same reason as the previous


#make a reg model to predict goal_met with Creator_nb_projects and Creator_nb_backed
#modelHyp1 <- lm(Goal_met ~ Creator_nb_projects + Creator_nb_backed, data = dataHyp1_2)

#make a logreg model to predict goal_met with Creator_nb_projects and Creator_nb_backed
#modelHyp1Log <- glm(Goal_met ~ Creator_nb_projects + Creator_nb_backed, data = dataHyp1_2, family = "binomial")
#summary(modelHyp1Log)



#Perform anova test on dataHyp1

#Anova_normal <- anova(modelHyp1)
#Anova_log <- anova(modelHyp1Log)

#stargazer::stargazer(list(Anova_normal, Anova_log), type = 'text')

#table output both Anova_normal and Anova_log inline using stargazer
```

### Some more cleaning and barplot creation

```{r}
#return the values of the loop in a vector
vec_val <- c()
vec_ind <- c()
vec_amount <- c()

for (i in 1:as.integer(max(dataHyp1$Creator_nb_projects))){
  vec_val[i] <- sum(dataHyp1$Goal_met[dataHyp1$Creator_nb_projects == i])/length(dataHyp1$Goal_met[dataHyp1$Creator_nb_projects == i])
  vec_ind[i] <- i
  vec_amount[i] <- length(dataHyp1$Goal_met[dataHyp1$Creator_nb_projects == i])
}

#create a table of vec_val and vec_ind as two columns with headers: index and percentage
tableHyp1 <- data.frame(vec_ind, vec_val, vec_amount)
tableHyp1



```

```{r}
#make a barplot of the column vec_amount
barplot(tableHyp1$vec_amount, names.arg = tableHyp1$vec_ind, xlab = "Number of projects", ylab = "Number of projects of the creator", main = "Number of projects of the creator by number of projects of the creator")

```

```{r}


#drop columns where nan exists
tableHyp1 <- tableHyp1[complete.cases(tableHyp1),]
# tableHyp1


#make a barchart of tableHyp1
barplot(tableHyp1$vec_val, names.arg = tableHyp1$vec_ind, xlab = "Number of projects", ylab = "Percentage of projects that met their goal", main = "Percentage of projects that met their goal by number of projects of the creator")


```

```{r}
#make a barchart of the number of projects per number of projects
barplot(tableHyp1$vec_amount, names.arg = tableHyp1$vec_ind, xlab = "Number of projects", ylab = "Number of projects of the creator", main = "Number of projects of the creator by number of projects of the creator")


```

```{r}

# Convert the data to numeric if needed
dataHyp1$Creator_nb_projects <- as.numeric(dataHyp1$Creator_nb_projects)

# Check if 'tableHyp1$vec_ind' is numeric or convert it
tableHyp1$vec_ind <- as.numeric(tableHyp1$vec_ind)

# Now, create the barplot
barplot(dataHyp1$Creator_nb_projects, names.arg = tableHyp1$vec_ind, xlab = "x", ylab = "y", main = "title")

#this code raises an error. 


```

## Results

### Hypothesis 1 results

```{r}

dataHyp1
dataHyp1$Creator_nb_projects
tableHyp1$vec_ind

```

Present the results of your analyses including descriptive statistics, regression tables, as well as any possible figures or visualizations that you made, e.g., those of the interaction effects.

## Discussion

What did we learn from what you found in your results, how do those findings relate to the ongoing debate in literature, and what can practitioners learn from that?

## Conclusion (?)

The description did not say a conclusion was needed, but I think it is a good idea to have one.

## References

the bib.tex file can go here. I have not yet added any references, but as we write they will be added.
