---
title: "SBM Report Group 4"
format: pdf
editor: visual
author: "Bram Kapteijns, Diego van den Hoeven, Roland Vits, Thomas Boot, Born√° Djavdan"
bibliography: references.bib
---

# Report SBM Group 4

## Introduction

Kickstarter is a crowdfunding platform where creators can share their ideas for a product or service to bring it to life. Creators can set a pledge goal, which they believe will ensure that the project will be a success; other users can pledge money. Creators have several ways to attract donators, for instance they could promise perks to those who donate, they could promise an improved product depending on the amount reached, and they could be more transparent about progress. Creating a successful project on this site might be considered a matter of luck to many; however, with the availability of a data set of this platform, it is possible to study a factor that could influence the success of a project.

Creators in Kickstarter can be seen as entrepreneurs of a business with the goal of providing a product or a service. Thus, an organizational framework can be used to see what factors are at play in determining a project's success. The behavioral theory of the firm is one such framework, and it allows for the study of how learning affects the firm [@cyert1963]. It is commonly believed that more experience leads to a better chance of success for a business [@Levitt][@PARKER], however there are those who argue against this notion [@blank], resulting in a contradicting literature. It is also interesting to study how experience affects the way that creators change their ideas, more specifically if their ideas become more or less innovative as they become more experienced. Entrepreneurial experience has been suggested to increase reported innovation [@Vaillant2019].

For this purpose, the following research questions were formulated:

RQ1: How does experience impact the success rate?

RQ2: How do business ideas change after experience?

## Theory and Hypotheses

The Behavioural Theory of the Firm theorizes how organisations operate based on coallitions of various participants. Each participant has their own goals and aspirations, and the firm's behaviour as a whole is a result of the equilibrium reached by the choices of the individuals, bargaining process between those individuals, and the selections they make [@cyert1963] [@Levitt].

However, the way an organization learns, though intertwined with these processes, can be framed differently. This framework, proposed by Levitt & March, focuses on three processes: behavior of organizations is based on routines, the actions of an organization are history-dependent, and organizations are goal oriented [@Levitt]. Levitt & March also suggest that organizations can learn from direct experience, and indirectly from the experience of others. Therefore it is important to take these two possibilities into account when studying organizational learning, as this research intends to do. This means that data on direct experience and indirect experience is necessary for the goals of this study.

### Research Question 1

The first research question relates to the idea of Organizational Learning developed by Levitt and March, given that it studies how KickStarter creators learn from their previous endevours and the experience of others. Given this focus on KickStarter creators, the research question is centered in the case of an entrepreneurial organization. Therefore, it builds on the theory presented by Parker, where it was found that serial entrepreneurs have an performance improvement due to gained experience. The study also concluded that the benefits of this experience diminished over time [@PARKER]. This research question also builds upon a study by Blank which found that, in the case of student startups, previous experience in entrepreneurship did not result in significant benefits for the survival of the startup when compared to advice given by a mentor. The explanation given for this was that previous experience would cause a tendency to imitate processes and routines that were tested in the past, which may harm the survival of the organization [@blank].

Given these contradictory results regarding past experience, we decided to formulate the hypothesis in line with the results of Parker, as the situation is more general and thus more applicable to the case of KickStarter. Thus the hypothesis is **people who have experience in starting companies will have more success than people who do not have this experience.**

### Research Question 2

The theoretical foundation of this research is grounded in the dynamic nature of entrepreneurial cognition and the impact of experiential learning on the evolution of business ideas. Entrepreneurial activities involve a continuous process of learning, adaptation, and refinement. According to cognitive theories of entrepreneurship, the experience gained through the implementation of an initial business idea contributes significantly to an entrepreneur's cognitive development [@marcati2008role]. The theoretical framework posits that as entrepreneurs engage in practical ventures, they accumulate knowledge, skills, and insights, thereby influencing the generation and transformation of subsequent business ideas [@marcati2008role]. The iterative nature of entrepreneurship suggests that learning from experience fosters a more sophisticated understanding of market dynamics, consumer needs, and effective business strategies. This accumulated knowledge is likely to lead to the generation of more innovative ideas over time. The theory is underpinned by the concept of the entrepreneurial learning cycle, emphasizing that the process of learning from experience enhances an entrepreneur's ability to conceive and implement innovative business ideas.

Building upon the theoretical framework, the hypothesis posits that **subsequent business ideas developed by entrepreneurs with prior experience are more innovative than their initial business idea**. This hypothesis is rooted in the belief that the knowledge gained from the practical implementation of the first idea contributes to an enhanced entrepreneurial mindset, characterized by a deeper understanding of market dynamics and a heightened ability to identify and capitalize on opportunities.

### Assumptions

To test both research questions and to validate both hypothesis, multiple assumptions are made. Firstly it is assumed that an entrepreneur does not have any prior experience before joining the database. When entrepreneurs have prior experience which is not covered in the data, the results will be skewed since the entrepreneurs with prior experience and new entrepreneurs can not be distinguished in the data.\
Secondly, we assume that the data in the database is sufficient and that there are no other, unmeasured, variables that influence the outcome of this research.\
Thirdly, to measure the succesrate, there is no explicit variable that measures succesrate. So, to measure succesrate, it is assumed that funding is a good proxy for succesrate. How successful a start-up is, is measured by the total raised funding divided by the funding goal. This will be a good approximation since projects where the funding goal is not reached will not get the money from Kickstarter and therefore can not start with their start-up.\
Fourthly, it is assumed that the data is unbiased because the data is collected by a third party.\
Fifthly, it is assumed that innovation-related words can also be taken as meaning innovation. By expanding the bucket of words referring to innovation we assure that the majority of the words related to innovation are covered.

Lastly, it is not assumed that employees influence business results, as we are taking a look at Kickstarter projects. And start-up culture is not the same as corporate culture. It is not assumed that the number of employees is a good proxy for experience, because the number of employees does not say anything about the experience of the employees [@martin2010].

## Methods and Data

Describe the data set that you used, the way you translated the raw data into variables, and the methods you used to analyze the data (e.g., cluster analysis, regression analysis, panel data analysis, time series). Remember that most methods have a number of assumptions that you have to check prior to doing the analyses. Certain assumption violations can be fixed by transforming the focal variables, e.g., the dependent variable, in case of other violations you may need to choose a different method

```{r}
getwd()
#setwd("C:/Users/bvits/OneDrive/Desktop/2023/Masters/JADs/strat bm/Project/SBM_assignment/report")
getwd()
```

### Data Importing and cleaning, research question 1

In order to test the first hypothesis it is necessary to first clean the data. The first step is to select the data that has a deadline is before week 32 in 2019 in unix time and make sure that the variables that will be used in the regression are of the correct class. Next, a percentage is derived from the pledge goal of the project and how much was actually pledged, this will be used as a measure of success. For this reason the projects with a pledge goal of 0 were removed, this avoids division by zero. It was also chosen that values that exceeded 100% would be set to this value, as these might be detected as outliers and could cause issues. After this, we check the distribution of the data and remove cases in which we don't have enough data for the number of projects backed and the number of projects created, which are proxies for learning in this study. We consider that having less than 50 data points is when the data point is removed, this is because 50 data points are the minimum for a normal distribution to be present (find citation). Finally, the null values are removed. The below shows the distribution of the learning proxies and the proxy for success.

```{r}
#inspect the data
#load .rds file named "info" into rstudio
info32<-readRDS('info.rds')

#create new data with only a few columns of info32 dataset
dataHyp1Sub <- info32[,c('Goal_USD','Pledge_USD','Launched_at',
                         'Deadline', 'Creator_nb_projects', 
                         'Creator_nb_backed')]
#dataHyp1Sub

#make a subdataset where deadline is before week 32 in 2019 in unix time
dataHyp1 <- dataHyp1Sub[dataHyp1Sub$Deadline < 1565474400,]
#dataHyp1

#You drop only 1850 records out of 75000


#columns to integer
dataHyp1$Pledge_USD <- as.integer(dataHyp1$Pledge_USD)
dataHyp1$Goal_USD <- as.integer(dataHyp1$Goal_USD)

#Remove NAs

dataHyp3<- na.omit(dataHyp1)


#drop the rows where Goal_USD is 0 -> then you might get inf percentage
dataHyp1 <- dataHyp1[dataHyp1$Goal_USD != 0,]
#dataHyp1

#Create a new column with percentage of goal reached
dataHyp1$Goal_percentage <- (dataHyp1$Pledge_USD/dataHyp1$Goal_USD)*100
dataHyp1$Goal_percentage <- round(dataHyp1$Goal_percentage, digits = 3)
dataHyp1$Goal_percentage[dataHyp1$Goal_percentage>100] = 100

table(dataHyp1$Goal_percentage[dataHyp1$Goal_percentage == 100])

#dataHyp1

#Get from Creator_nb_backed only the number with a regex
dataHyp1$Creator_nb_backed <- gsub("[^0-9]", "", dataHyp1$Creator_nb_backed)
#Seeing if this works better as a string rather than an integer
#dataHyp1

#drop redundant columns
dataHyp1 <- dataHyp1[,c('Creator_nb_projects', 'Creator_nb_backed', 
                        'Goal_percentage')]


#Drop the rows where nan values occur
dataHyp1 <- dataHyp1[complete.cases(dataHyp1),]


#to find an appropriate cutoff point:

# we will only use values with at least 50 records, 
# because for normal distribution you need a minimum of 50 values
# So then you have an substantial amount of values


#iterate over the values of the following table: 
#table(dataHyp1$Creator_nb_projects)
quan_table1 = table(dataHyp1$Creator_nb_projects)
quan_table2 = table(dataHyp1$Creator_nb_backed)

#in quan_table, drop the records where the value is < 50
quan_table1 <- quan_table1[quan_table1 >= 50]
quan_table2 <- quan_table2[quan_table2 >= 50]

#clean the data such that only records with over 50 occurences are in there
dataHyp1_2 <- dataHyp1[dataHyp1$Creator_nb_projects %in% names(quan_table1),]
dataHyp1_2 <- dataHyp1[dataHyp1$Creator_nb_backed %in% names(quan_table2),]

#drop nan and inf values in dataHyp1_2
dataHyp1_2 <- dataHyp1_2[complete.cases(dataHyp1_2),]

hist(as.numeric(dataHyp1_2$Creator_nb_projects), 
     main = 'Histogram of Number of Projects Created (learning)', 
     xlab = 'Number of Projects Created')




```

```{r}
hist(as.numeric(dataHyp1_2$Creator_nb_backed),
     main = 'Histogram of Number of Projects Backed (learning)', 
     xlab = 'Number of Projects Backed')
```

```{r}
hist(dataHyp1_2$Goal_percentage, 
     main = 'Histogram of the Percentage of the Goal Reached (success)',
     xlab = 'Percentage of Goal Reached')
```

The above figure shows that the success proxy, the percentage of the Kickstarter goal that was reached, is not normal, so a couple of transformations are tried, as for linear regression a normal outcome variable is required. First Log(x+1) is tried, given that 0% is still viable, this shift is necessary to avoid undefined values. Next sqrt(Log(x+1)) is applied, but even though it is better, with the QQ-plots below we notice that it is still not normally distributed. The first QQ-plot corresponds to Log(x+1) and the second is for sqrt(Log(x+1)). Therefore a Linear Regression model cannot be used.

```{r}
x<-dataHyp1_2$Goal_percentage
#looks exponential, so we try log transform
y<-log(dataHyp1_2$Goal_percentage+1)
qqnorm(y)
qqline(y)


```

```{r}
#still skewed, so we try to include sqrt transform
y<-sqrt(log(dataHyp1_2$Goal_percentage+1))
qqnorm(y)
qqline(y)
```

### Regression and Anova test, research question 1

Given that the data is not normally distributed, and the tested transformations are not satisfactory a linear regression is not appropriate. By looking at the previous histogram, we can asses that the data seems to be from an exponential distribution with an inflated 0 value. Therefore, Poisson regression Gamma regression, and zero inflated regression are tried. For poisson regression, we round the goal percentage to the nearest integer, given that the model works for discrete outcome variables. It is also important to note that the zero inflated value model did not converge, regardless of the preprocessing steps taken for this regression. The first step was hot-encoding the proxies for learning because the model doesn't take factors as inputs, then the percentages for the success were rounded to integers because the model only outputs integers. The possible reasons as to why this error still occured will be presented in the discussion section.

```{r}

##LM
modelLinear <- lm(Goal_percentage ~ Creator_nb_projects + 
                     Creator_nb_backed, 
                   data = dataHyp1_2)

par(mfrow = c(2,2), col.axis = "black", col.lab = "black", tck = 0)

plot(modelLinear, which = 1)  # Residuals vs Fitted
plot(modelLinear, which = 2)  # Normal Q-Q plot
plot(modelLinear, which = 3)  # Scale-Location plot
plot(modelLinear, which = 4)  # Residuals vs Leverage


```

```{r}

dataHyp1_2$Goal_percentage_logtransfromed<-log(dataHyp1_2$Goal_percentage+1)

modelLinear2 <- lm(Goal_percentage_logtransfromed ~ Creator_nb_projects + 
                     Creator_nb_backed, 
                   data = dataHyp1_2)

par(mfrow = c(2,2), col.axis = "black", col.lab = "black", tck = 0)

plot(modelLinear2, which = 1)  # Residuals vs Fitted
plot(modelLinear2, which = 2)  # Normal Q-Q plot
plot(modelLinear2, which = 3)  # Scale-Location plot
plot(modelLinear2, which = 4)  # Residuals vs Leverage


```

```{r}

dataHyp1_2$Goal_percentage_sqrttransfromed<-sqrt(log(dataHyp1_2$Goal_percentage+1))

modelLinear3 <- lm(Goal_percentage_sqrttransfromed ~ Creator_nb_projects + 
                     Creator_nb_backed, 
                   data = dataHyp1_2)

par(mfrow = c(2,2), col.axis = "black", col.lab = "black", tck = 0)

plot(modelLinear3, which = 1)  # Residuals vs Fitted
plot(modelLinear3, which = 2)  # Normal Q-Q plot
plot(modelLinear3, which = 3)  # Scale-Location plot
plot(modelLinear3, which = 4)  # Residuals vs Leverage
```

```{r}
##non integer

##try Gamma distribution

# dataHyp1_2$nonzero_percentage <- dataHyp1_2$Goal_percentage + 1e-6
# modelGamma  <- glm(nonzero_percentage ~ Creator_nb_projects + 
#                      Creator_nb_backed, 
#                    data = dataHyp1_2,family = 
#                      Gamma(link = 'identity'))


dataHyp1_2$Goal_reached<- as.integer(floor(dataHyp1_2$Goal_percentage*0.01))

table(dataHyp1_2$Goal_reached)
##logistic distribution

modelLogistic <- glm(Goal_reached ~ Creator_nb_projects + Creator_nb_backed, 
                       data = dataHyp1_2,
                       family = binomial(link = 'logit'))


# trying zero inflation model
##can't use factors, need to one hot encode



# hot_encode <- model.matrix(~  Creator_nb_projects + Creator_nb_backed  - 1, 
#                            data = dataHyp1_2)
# 
# hot_encode<-as.data.frame(hot_encode)

##can't use non integer values for the dependent variable

# inflDS <- cbind(dataHyp1_2$Goal_percentage, 
#                 hot_encode)

#don't run this if the second zeroinfl will be runned (it will cause issues with removing values to try to avoid skeweness)
# inflDS$percent_int<- as.integer(round(inflDS$`dataHyp1_2$Goal_percentage`,0))
# 
# null_values_per_column <- sapply(inflDS, 
#                                  function(x) any(is.na(x)))

# Print the result

##doesn't converge
#modelZeroINFL_1 <- pscl::zeroinfl(percent_int ~ . - `dataHyp1_2$Goal_percentage` | . - `dataHyp1_2$Goal_percentage`, dist = "geometric", data = inflDS, control = pscl::zeroinfl.control(maxit = 100000))

##try to remove skeweness by ignoring certain values (between 0 an 1, to avoid having too much data)

#inflDS<- inflDS[!(inflDS$`dataHyp1_2$Goal_percentage` > 0 & inflDS$`dataHyp1_2$Goal_percentage` < 1), ]
#inflDS$percent_int<- as.integer(round(inflDS$`dataHyp1_2$Goal_percentage`,0))


##doesn't converge either
#modelZeroINFL_2 <- pscl::zeroinfl(percent_int ~ . - `dataHyp1_2$Goal_percentage` | . - `dataHyp1_2$Goal_percentage`, dist = "geometric", data = inflDS, control = pscl::zeroinfl.control(maxit = 100000))
#summary(modelZeroINFL)

```

### Data Importing and cleaning, research question 2

First let us describe the data necessary for the second research question. We use the same dataset as the for the first research question: the kickstarter dataset. Besides a score for innovation, which we will discuss later, we used the following variables: - The number of projects that preceded this one (for the same entrepreneur). We made this both a number and a factor, to account for a decreasing effect as the number of observations decreased; - The number of dollars that the project aimed to achieve; - The duration of the project; - The success of the preceding project, which we defined as the number of dollars that project received divided by the number of dollars it aimed to achieve; - The category of the project (which is similar to the industry of the project) as control variables. Because of the pareto distribution that is generally considered to be present in income, we took the log values of the number of dollars that projects aimed to achieve and achieved [@pareto].

```{r}
# Install and load required packages
# install.packages(c("tidytext", "dplyr", "ggplot2"))
library(tidytext)
library(dplyr)
library(ggplot2)

#inspect the data
info_filename <- file.choose()
info <- readRDS(info_filename)

#create a dataset with only creator_slug that appear more than once in the dataset
dataHyp2Double <- info[info$creator_slug %in% names(which(table(info$creator_slug) > 1)),]

dataHyp2sub<- dataHyp2Double[,c('creator_slug','Goal_USD',
                                'Pledge_USD','Launched_at',
                                'Deadline','Project_description',
                                'Creator_nb_projects','Creator_nb_backed', 
                                'Category')]

dataHyp2filtered <- na.omit(dataHyp2sub)

#make a subdataset where deadline is before week 32 in 2019 in unix time
dataHyp2 <- dataHyp2filtered[dataHyp2filtered$Deadline < 1565474400,]


#make a new column with boolean if goal_USD >= Pledge_USD
dataHyp2$Pledge_USD <- log(as.numeric(dataHyp2$Pledge_USD) + 1)
dataHyp2$Goal_USD <- log(as.numeric(dataHyp2$Goal_USD) + 1)
dataHyp2$success_rate <- dataHyp2$Pledge_USD / dataHyp2$Goal_USD

dataHyp2 <- subset(dataHyp2, is.finite(dataHyp2$Pledge_USD) 
                   & is.finite(dataHyp2$Goal_USD) 
                   & is.finite(dataHyp2$success_rate))

# make a new column with order which orders the projects per creator_slug based on launched_at.
# So the first project of a creator should get 1, the second 2 ..
dataHyp2 <- dataHyp2 %>%
  arrange(Launched_at) %>%
  group_by(creator_slug) %>%
  mutate(Order = row_number())

dataHyp2$duration <- as.numeric(dataHyp2$Deadline) - as.numeric(dataHyp2$Launched_at)

dataHyp2$orderFactor <- as.factor(dataHyp2$Order)

dataHyp2 <- dataHyp2 %>%
  arrange(creator_slug, Order) %>%  # Sort the dataframe by 'id' and 'order'
  group_by(creator_slug) %>%
  mutate(previousSuccess = lag(success_rate, default = 1))
```

### Defining innovation, research question 2

Since our dependent variable is innovation, we need to have a measure for innovation. We got our measure for innovation from the description of the project. Using a CAT scanner for innovation, which is a corpus of scientifically verified innovation-related words, we gave an innovation metric to the description, which became the innovation metric for the entire project [@McKenny2018]. We used the existence of these words as the measure, and more of these words means a higher measure.

```{r}
word_dict <- c( "ad lib", "adroit", "adroitness", "bright idea", "clever", "cleverness", "conceive", "concoct", "concoction", "concoctive", "conjure up", "creative", "creativity", "develop", "developed", "dream", "dream up", "expert", "formulation", "freethinker", "genesis", "genius", "gifted", "hit upon", "imagination", "imaginative", "improvise", "ingenious", "ingenuity", "innovate", "innovated", "innovates", "innovating", "innovation", "innovations", "innovative", "innovativeness", "introduced", "introducing", "introduction", "introductions", "invent", "invented", "invention", "inventive", "inventiveness", "inventor", "launch", "launched", "launching", "master stroke", "mastermind", "metamorphose", "metamorphosis", "neoteric", "neoterism", "neoterize", "new capabilities", "new capability", "new compounds", "new content", "new core areas", "new course", "new directions", "new family", "new features", "new generation", "new generations", "new idea", "new ideas", "new line of business", "new medicine", "new medicines", "new molecular entities", "new pharmaceuticals", "new platform", "new process", "new processes", "new product", "new products", "new solutions", "new systems", "new technique", "new techniques", "new technologies", "new technology", "new therapies", "new thinking", "new tools", "new treatments", "new ways", "new wrinkle", "new-generation", "new-product", "next generation", "next-generation", "novation", "novel", "novelty", "patent", "patented", "patents", "process development", "product development", "product launch", "product launches", "proprietary", "prototype", "prototyping", "push the envelope", "R&D", "radical", "re-engineering", "reformulated", "refreshed", "reinvent", "re-invent", "reinvented", "reinventing", "reinvention", "reinvents", "released", "renewal", "renewing", "research", "reshape", "reshaped", "reshapes", "reshaping", "resourceful", "resourcefulness", "restyle", "restyling", "revolutionary", "revolutionize", "revolutionized", "roll out", "rolled out", "see things", "technologically advanced", "think up", "trademark", "transform", "transformation", "transformed", "transforming", "visualize")

innovation_ratios <- vector(mode='numeric', length=nrow(dataHyp2))
for (i in 1:nrow(dataHyp2)) {
  innovation_counter <- 0
  for (word in word_dict) {
    innovation_counter <- innovation_counter + stringr::str_count(dataHyp2$Project_description[i], paste("(?i)", word, sep=''))
  }
  innovation_ratios[i] <- innovation_counter/stringr::str_count(dataHyp2$Project_description[i], ' ')
}

dataHyp2$innovation <- innovation_ratios * 1000
```

### Defining linear models, research question 2

The variables mentioned in the section discussing the importing and cleaning of the data discussed the variables that we took into consideration. We investigated the impact on innovation for each of those variables separately (mod0 to mod5), and then added the variables together iteratively. We did not investigate all combinations, because this would take too much effort. We made a couple of models, based on our intuition of relevant parameters. We then plot the models.

```{r}

mod0 <- lm(innovation ~ Order, data=dataHyp2)
# mod1 <- lm(innovation ~ orderFactor, data=dataHyp2)
mod1 <- lm(innovation ~ Goal_USD, data=dataHyp2)
mod2 <- lm(innovation ~ duration, data=dataHyp2)
mod3 <- lm(innovation ~ previousSuccess, data=dataHyp2)
# mod5 <- lm(innovation ~ Category, data=dataHyp2)

modA <- lm(innovation ~ Order + Goal_USD + 
             duration, data=dataHyp2)
#modB <- lm(innovation ~ orderFactor + Goal_USD + 
#             duration, data=dataHyp2)
modB <- lm(innovation ~ Order + Goal_USD + 
             duration + previousSuccess, 
           data=dataHyp2)
#modD <- lm(innovation ~ orderFactor + Goal_USD + 
#             duration + previousSuccess, 
#           data=dataHyp2)
modC <- lm(innovation ~ Order + Goal_USD + 
             duration + previousSuccess + 
             previousSuccess * Order, 
           data=dataHyp2)
#modF <- lm(innovation ~ orderFactor + Goal_USD + 
#             duration + previousSuccess * orderFactor
#           , data=dataHyp2)
#modG <- lm(innovation ~ Order + Goal_USD + duration +
#             previousSuccess + previousSuccess * Order
#           + Category, data=dataHyp2)
#modH <- lm(innovation ~ orderFactor + Goal_USD + duration +
#             previousSuccess * orderFactor + Category, 
#           data=dataHyp2)

#texreg::screenreg(list(mod0, mod1, mod2, mod3, mod4, mod5, modA, 
#                       modB, modC, modD, modE, modF, modG, modH))

texreg::screenreg(list(mod0, mod1, mod2, mod3))


```

```{r}
texreg::screenreg(list(modA, modB, modC))
```

```{r}
par(mfrow = c(2,2), col.axis = "black", col.lab = "black", tck = 0)

plot(mod0, which = 1)  # Residuals vs Fitted
plot(mod0, which = 2)  # Normal Q-Q plot
plot(mod0, which = 3)  # Scale-Location plot
plot(mod0, which = 4)  # Residuals vs Leverage
```

```{r}
par(mfrow = c(2,2), col.axis = "black", col.lab = "black", tck = 0)

plot(mod1, which = 1)  # Residuals vs Fitted
plot(mod1, which = 2)  # Normal Q-Q plot
plot(mod1, which = 3)  # Scale-Location plot
plot(mod1, which = 4)  # Residuals vs Leverage
```

```{r}
par(mfrow = c(2,2), col.axis = "black", col.lab = "black", tck = 0)

plot(mod2, which = 1)  # Residuals vs Fitted
plot(mod2, which = 2)  # Normal Q-Q plot
plot(mod2, which = 3)  # Scale-Location plot
plot(mod2, which = 4)  # Residuals vs Leverage
```

```{r}
par(mfrow = c(2,2), col.axis = "black", col.lab = "black", tck = 0)

plot(mod3, which = 1)  # Residuals vs Fitted
plot(mod3, which = 2)  # Normal Q-Q plot
plot(mod3, which = 3)  # Scale-Location plot
plot(mod3, which = 4)  # Residuals vs Leverage
```

```{r}
par(mfrow = c(2,2), col.axis = "black", col.lab = "black", tck = 0)

plot(modA, which = 1)  # Residuals vs Fitted
plot(modA, which = 2)  # Normal Q-Q plot
plot(modA, which = 3)  # Scale-Location plot
plot(modA, which = 4)  # Residuals vs Leverage
```

```{r}

par(mfrow = c(2,2), col.axis = "black", col.lab = "black", tck = 0)

plot(modB, which = 1)  # Residuals vs Fitted
plot(modB, which = 2)  # Normal Q-Q plot
plot(modB, which = 3)  # Scale-Location plot
plot(modB, which = 4)  # Residuals vs Leverage

```

```{r}
par(mfrow = c(2,2), col.axis = "black", col.lab = "black", tck = 0)

plot(modC, which = 1)  # Residuals vs Fitted
plot(modC, which = 2)  # Normal Q-Q plot
plot(modC, which = 3)  # Scale-Location plot
plot(modC, which = 4)  # Residuals vs Leverage
```

```{r}
# texreg::screenreg(list(mod0, mod2, mod3, mod4, modA, modC, modE))
```

### Plotting innovation graphs

Besides fitting a linear model, we also made graphs showing the impact of having multiple projects on the mean innovation and change in innovation compared to having one less project.

```{r}
dataHyp2 <- dataHyp2 %>%
  arrange(creator_slug, Order) %>%  # Sort the dataframe by 'id' and 'order'
  group_by(creator_slug) %>%
  mutate(change = innovation - 
           lag(innovation, default = first(innovation)))


```

```{r}
dataHyp2 %>% ggplot(aes(x=factor(Order), y=change)) +
  geom_boxplot() +
  geom_line(stat="summary", fun="mean",
            aes(group=1, y=innovation),
            color="red", size=1) +
  labs(title="Change in innovation for number of projects",
       x="Number of projects",
       y="Change in innovation compared to time-1")


```

```{r}
ggplot(dataHyp2, aes(x = Order, y = change)) +
  geom_bar(stat = "summary", fun = "mean", 
           position = "dodge") +
  labs(title = "Mean change in innovation for number of projects", 
       x = "Number of projects", y = "Innovation")


```

```{r}
dataHyp2 %>% ggplot(aes(x=factor(Order), y=innovation)) +
  geom_boxplot() +
  labs(title="Innovation for number of projects",
       x="Number of projects",
       y="Innovation")

```

```{r}
ggplot(dataHyp2, aes(x = Order, y = innovation)) +
  geom_bar(stat = "summary", fun = "mean", position = "dodge") +
  labs(title = "Mean innovation for number of projects",
       x = "Number of projects", y = "Innovation")
```

## Results

### Hypothesis 1 results

#### Logistic model

Given that the zero inflated model doesn't produce results, we proceed by studying the Poisson model. First we look at the results for the Poisson Model.

```{r}
##Logistic summary
summary(modelLogistic)


```

```{r}
#summary(anova(modelLogistic))
```

From the results we see that most of the coefficients for both the number of backed projects and the number of projects created are significant. This suggests that the effects of the proxies we selected for learning are significant. In regards to the sign of the coefficients, we notice that none of the negative values are significant, with the exception of the intercept. Since the significant coefficients are positive, though small, we conclude that learning has a positive effect on success, which is in line with (find citation). In this case we don't notice an increasing pattern in of the coefficients, wherein more experience would have significantly higher values, as sometimes the coefficients decrease again.

```{r}
library(plot3D)
plot_probs <- function(model, var1, var2, n = 50, ...) {
  nm1 <- deparse(substitute(var1))
  nm2 <- deparse(substitute(var2))
  df <- model.frame(model)
  var1 <- df[[nm1]]
  var2 <- df[[nm2]]
  df <- df[-match(c(nm1, nm2), names(df))]
  preds <- list(x = seq(min(var1), max(var1), length = n),
                y = seq(min(var2), max(var2), length = n))
  predlist <- setNames(c(preds, lapply(df, mean)), c(nm1, nm2, names(df)))
  pred_df <- do.call("expand.grid", predlist)
  Probability <- matrix(predict(model, newdata = pred_df, type = "response"), 
                        nrow = n)
  persp(x = preds$x, y = preds$y, z = Probability, xlab = nm1, ylab = nm2,
        ticktype = "detailed", zlim = c(0, 1), ...)
}
```

```{r}
plot_probs(modelLogistic, Creator_nb_projects, Creator_nb_backed, theta = -60, phi = 30, col = "gold", cex.lab=0.7, cex.axis=0.6)
```

```{r}
dataHyp1_2$Creator_nb_projects <- as.numeric(dataHyp1_2$Creator_nb_projects)
dataHyp1_2$Creator_nb_backed <- as.numeric(dataHyp1_2$Creator_nb_backed)

modelLogistic <- glm(Goal_reached ~ Creator_nb_projects + Creator_nb_backed, 
                       data = dataHyp1_2,
                       family = binomial(link = 'logit'))


# Add predicted probabilities to your dataset
dataHyp1_2$prob <- predict(modelLogistic, newdata = dataHyp1_2, type = "response")

# Ensure all variables are numeric and remove any rows with NA values
dataHyp1_2 <- na.omit(dataHyp1_2)

# Now plot with plot3D::scatter3D
plot3D::scatter3D(x = dataHyp1_2$Creator_nb_projects, 
                  y = dataHyp1_2$Creator_nb_backed, 
                  z = dataHyp1_2$prob, 
                  xlab = "Number of Projects Created", 
                  ylab = "Number of Projects Backed", 
                  zlab = "Probability of Reaching Goal", 
                  colvar = dataHyp1_2$prob, 
                  col = rainbow(100), 
                  pch = 19, 
                  theta = -60, # Rotate horizontally
                  phi = 30, # Rotate vertically
                  cex.lab=0.4)    

plot_probs(modelLogistic, Glucose, BMI, theta = 45, phi = 30, col = "gold")

plot3D::slice3D(x = dataHyp1_2$Creator_nb_projects, y = dataHyp1_2$Creator_nb_backed, z = dataHyp1_2$prob, 
                  facets = NA, 
                  add = TRUE, 
                  col = "lightblue", 
                  alpha = 0.5)

```

```{r}
stargazer::stargazer(modelLogistic, title = "Research Question 1: Logistic Model", align = TRUE)
```

In the analysis of deviance table we notice that the inclusion of the number of projects backed reduces the deviance by a large margin, this justifies including these variables in the model, as it results in a better model.

```         
```

For this model, we notice that the coefficients are not mostly significant in the case of the number of projects created; contrastingly, the number of projects backed does have mostly significant values. It is also important to note that this Gamma distribution model has a lower AIC than the Poisson distribution model. We also notice that if the values are placed in increasing order of the amounts projects back and of the number of projects created there is an increase in the coefficients. This suggests that the more experience one has, the better they tend to perform. We also notice that the values that don't follow this tendency don't have significant p-values

```{r}
stargazer::stargazer(anova(modelGamma), title = "Research Question 1: Gamma Model", align = TRUE)
```

In this second analysis of deviance table, a similar effect is noticed to the previous, including the number of projects backed improves the model by reducing the deviance, which suggests that it's a good variable for the model. Therefore we can say that the success is not just explained by the experience one gains by doing more projects, but also observing the projects of others.

#### Justification of Results

The hypothesis that was studied stated that the more experience one has, whether direct or indirect, the more success one will have. However, the benefit that one sees from this has diminishing returns. A possible explanation for this could be similar to what Parker stated, that is if re-entry to entrepreneurship takes too long, the benefits on receives diminishes [@PARKER]. This could be due to forgetting past experiences, or the experiences becoming outdated in the ever changing environment in markets. This means that having too many past experiences implies that not all of the experiences will be used, as the gap between the earliest and the latest could be too wide, explaining why the coefficients in the regression seem to increase minimally after having some experience. Another explanation for this could simply be that there is not enough data on those who have a high amount of experience.

### Hypothesis 2 results

#### Linear models

Let us first discuss the results from the linear models. Using a significance level of 0.05, which is justified since we are not dealing with a critical situation, we can see that in all linear models, the number of previous projects (the 'Order' term) has a significant effect on the innovation score of projects. We can also see that this effect is negative. This means that the more projects a creator has done, the less innovative a new project is expected to be. As said in the methods section, we also added the number of previous projects as a factor (the 'orderFactor' term). Without any control variables, we can see that as projects get more previous projects, the innovation score gets lower. However, after adding the control variables, the effect of 'orderFactor' was no longer determined to be significant.

Comparing the models, it stands out that the 'category' term greatly increases the R-squared metric. We also see that a lot of categories significantly differ from the baseline category. We hypothesize that this means that some categories are more more likely to be innovative than others.

```{r}
#this will be the stargazer output of the second research question
stargazer::stargazer(mod0, mod1, mod2, mod3, title = "Research Question 2: Model 0 to 3", align = TRUE)

stargazer::stargazer(modA, modB, modC, title = "Research Question 2: Model 0 to 3", align = TRUE)
```

#### Plots

Looking at the plots, we are unable to see a clear trend. From our visual interpretations of the plots of the change in innovativeness. In the first plot, the red line seems to show that the number of projects slightly increases the innovation: the projects are - on average - slightly more innovative that the previous one, for the same entrepreneur. However, the effect seems to be very small, and there are lots of projects that are a lot less innovative than the previous ones for the same entrepreneur.

From the plots showing the mean innovation score for every project, we can see that as entrepreneurs have more previous projects, the projects become less innovative, on average. This seems to be in contrast with the first plots, showing the change in innovation. This could be explained by the fact that innovative products are more difficult to produce and thus take longer. This would mean that people that make more innovative products are not able to do as many projects. This also implies that projects with a lot of previous projects only occur when the entrepreneur does not do innovative projects (because they simply take too long to complete).

#### Justification of the results

We hypothesized that people with more previous projects, would be more innovative that people with fewer previous projects. However, we found the opposite effect. This could be due to the fact that people with lots of previous projects may be entrenched in their communities. This could make them behave as 'imitative entrepreneurs' [@CLIFF2006633].

As we said in the previous section, the effect can also be explained by the fact that projects with more previous projects can only be done by entrepreneurs that are less innovative. So this would mean that an increase in the number of projects is not the cause of an increase in innovativeness, but that an increase in number of projects is only possible for entrepreneurs that are not as innovative: instead of describing the effect of the number of projects, we described a feature of the data.

## Discussion

In this report we have found that, in the context of Kickstarter, entrepreneurs who become more experienced tend to become more successful in the endeavor of obtaining funding from users of the platform, though the benefits gained from the experience are not permanent. As mentioned previously, this is in accordance to the results of Parker's article [@PARKER] and seem to contradict the fact that experience does not affect success, as shown by Blank [@blank]. This study however does not definitively disprove or prove the previous results though, as it is centered around the context of Kickstarter, and thus suggests that more research must be done in the area of organizational learning to determine if more experience improves the odds of success of an entrepreneur's project.

It was also shown that Kickstarter entrepreneurs tend towards being less innovative as they become more experienced. This might be caused by them becoming "imitative entrepreneurs" as proposed by [@CLIFF2006633]. Therefore, this report solidifies Cliff's findings and expands the literature into the digital entrepreneurship which Kickstarter is a part of. It is then important that entrepreneurs are able to keep this in mind, as in the search for success one might try to gain experience on what successful projects may look like which could foster less innovative ideas. So a balance between experience and innovativeness must be struck, as without innovativeness it seems intuitive to say that the market will become saturated, thus decreasing chances of success.

This contradictory nature of becoming more experienced to achieve success, while becoming less innovative, which saturates the market, creates interesting room for discussion about the balance between experience and innovativeness: how does innovation impact the probabilities for success. A study by Hult [@HULT] found that innovativeness improves performance of businesses and is thus an aspect businesses must retain. It is therefore of interest to future research to study the effect of both experience and innovativeness on success, for example: does one supersede the other?

### Limitations

The study of the first research question in this project was limited by the fact that there aren't many people who back a large amount of projects and are creators of projects at the same time. This means that the data gets skewed, and not many creators make it past backing 10 other projects, meaning that it is difficult to measure indirect experience. Similarly, most creators don't make many projects, the great majority making just 1 project. This again produces biases in the data as we can't say that there are many experienced users. An attempt to mitigate this was attempted through the use of generalized linear models such as the poisson linear model and the gamma linear model as these account for right skewed distributions.

In regards to the second research question it is important to consider that an innovative project may take more time to complete as building the product may take longer, regardless of what the campaign duration is. This means that entrepreneurs that are more likely to do innovative projects will have done fewer projects in total, and on the contrary creators with a lot of previous projects are almost all not innovative. This also produces biases in the data set, and given that the Kickstarter data set doesn't contain data on how long it takes for the product to be launched after the pledge goal is reached, more information is needed for an improvement to be made.

The fact that very few creators make a large amount of projects is also a limitation for the second research question given that it looks at the number of previous successes. Therefore, if there isn't a representative enough sample of creators that made a large amount of projects the data set contains a bias. This bias affects the results of the model and must be considered when viewing the results provided by the models that were created.

## Conclusion

In conclusion, this report set out to answer questions about whether or not experience impacts entrepreneurs in regards to success and to innovativeness. The results show that experience is a positive predictor of success, but a negative predictor of innovativeness in entrepreneurs in the kickstarter dataset. The results regarding success suggest that further research needs to be made in order to conclusively decide whether this is the case of entrepreneurs as a whole and not just in Kickstarter. The results regarding innovativeness suggest that research can be made in order to see what the trade off between experience and innovativeness is, and how to maximize the success of a business by taking this into account.

## References

::: {#refs}
1.  Arnold, Barry C. 2015. "Pareto Distribution." In Wiley StatsRef: Statistics Reference Online, 1--10. John Wiley & Sons, Ltd. <https://doi.org/https://doi.org/10.1002/9781118445112.stat01100.pub2>.

2.  Blank, Tali Hadasa. 2021. "When Incubator Resources Are Crucial: Survival Chances of Student Startups Operating in an Academic Incubator." The Journal of Technology Transfer 46 (6): 1845--68. <https://doi.org/10.1007/s10961-020-09831-4>.

3.  Cliff, Jennifer E., P. Devereaux Jennings, and Royston Greenwood. 2006. "New to the Game and Questioning the Rules: The Experiences and Beliefs of Founders Who Start Imitative Versus Innovative Firms." Journal of Business Venturing 21 (5): 633--63. <https://doi.org/https://doi.org/10.1016/j.jbusvent.2005.02.010>.

4.  Cyert, Richard Michael, and James G. March. 1963. A Behavioral Theory of the Firm. Prentice-Hall.

5.  Hult, G.Tomas M., Robert F. Hurley, and Gary A. Knight. 2004. "Innovativeness: Its Antecedents and Impact on Business Performance." Industrial Marketing Management 33 (5): 429--38. <https://doi.org/https://doi.org/10.1016/j.indmarman.2003.08.015>.

6.  Levitt, Barbara, and James G. March. 1988. "Organizational Learning." Annual Review of Sociology 14: 319--40. <http://www.jstor.org/stable/2083321>.

7.  Marcati, Alberto, Gianluigi Guido, and Alessandro M Peluso. 2008. "The Role of SME Entrepreneurs' Innovativeness and Personality in the Adoption of Innovations." Research Policy 37 (9): 1579--90.

8.  Martin, Frank, and Ronnie Smith. 2010. "What Is It That Entrepreneurs Learn from Experience?" Industry and Higher Education 24 (6): 505--12. <https://doi.org/10.5367/ihe.2010.0016>.

9.  McKenny, Aaron F., Herman Aguinis, Jeremy C. Short, and Aaron H. Anglin. 2018. "What Doesn't Get Measured Does Exist: Improving the Accuracy of Computer-Aided Text Analysis." Journal of Management 44 (September): 2909--33. <https://doi.org/10.1177/0149206316657594>.

10. Parker, Simon C. 2013. "Do Serial Entrepreneurs Run Successively Better-Performing Businesses?" Journal of Business Venturing 28 (5): 652--66. <https://doi.org/https://doi.org/10.1016/j.jbusvent.2012.08.001>.

11. Vaillant, Yancy, and Esteban Lafuente. 2019. "Entrepreneurial Experience and the Innovativeness of Serial Entrepreneurs." Management Decision 57 (November): 2869--89. <https://doi.org/10.1108/MD-06-2017-0592>.
:::

## Appendix

The github can be accessed through the following link: https://github.com/Bero898/SBM_assignment.git
